{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc8cff84",
   "metadata": {},
   "source": [
    "По моему мнению, данные для таблицы взяты с сайта www.metacritic.com, так как путем проверки найдены совпадения. Проблема в том, что сайт блокирует попытки парсинга его данных, поэтому я обратился к сайтам, аффилированным с ним, точнее к www.gamespot.com.\n",
    "Они оба принадлежат одной группе.  \n",
    "КПД парсера составило около 20%, так как сайт форматирует названия игр из таблицы по своему усмотрению и нужна кропотливая ручная работа по составлению ссылок.   \n",
    "Из 324 удачных запросов по играм, у которых нет пропусков, обнаружено 228 совпадения, а максимальное отличие не превышает 5%.\n",
    "По пользовательским оценкам данные различаются сильнее, так как аудитории разные. Среднее оклонение рейтинга получилось 0.8\n",
    "Сама работа парсера медленная, чтобы запросить 7312 игр нужно три часа.\n",
    "\n",
    "Также прилагается парсер сайта ESRB.com для пользовательских рейтингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c578ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Чтобы снизить вероятность того, что клиентский сервер примет вас за бота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ab14fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fake-useragent in c:\\anaconda\\envs\\scrapingenv\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: importlib-resources>=5.0 in c:\\anaconda\\envs\\scrapingenv\\lib\\site-packages (from fake-useragent) (5.12.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\anaconda\\envs\\scrapingenv\\lib\\site-packages (from importlib-resources>=5.0->fake-useragent) (3.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fake-useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df66d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fbc193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Приведение колонок с текстовой информацией к нижнему регистру\n",
    "text_cols = ['name', 'platform', 'genre','rating']\n",
    "for col in text_cols:\n",
    "    data[col] = data[col].str.lower()\n",
    "    \n",
    "# Создание списка игр, информацию о которых нужно уточнить\n",
    "games_to_find = data[data.isnull().any(axis=1)]['name'].unique() \n",
    "\n",
    "domain = r'https://www.gamespot.com/games'   #домен сайта\n",
    "formatted_names = [] #Список отформатированных имен, которые принимает сайт в адресной строке браузера\n",
    "list_of_links = []   #список ссылок на игры\n",
    "\n",
    "#Преобразование имен из таблицы в формат, принимаемый сайтом\n",
    "for name in games_to_find:\n",
    "    name = str(name) #конвертировать в тип строки, чтобы превратить точку у числе типа float в конце просто в точку\n",
    "    name = name.strip(' ')\n",
    "    #замена символа & на and\n",
    "    name = re.sub('[&]+', 'and', str(name))\n",
    "    #замена любых символов, кроме букв и цифр на дефисы\n",
    "    name = re.sub('[^A-Za-z0-9]+', '-', str(name))\n",
    "    name = re.sub('[-, /]*$','',str(name))\n",
    "    formatted_names.append(name)\n",
    "    link = domain+'/'+name    #построение ссылки\n",
    "    list_of_links.append(link) #добавление ссылки в список\n",
    "\n",
    "#Словарь ссылок и названий    \n",
    "names_links_pairs = dict(zip(list_of_links, games_to_find))\n",
    "\n",
    "##--------------------ТЕЛО ПАРСЕРА------------------------------\n",
    "exception_list = [] # Список, куда будут заноситься названия, ссылки и ошибки \n",
    "game_info = {}   #Словарь, который будет создан парсером с нужной информацией\n",
    "main_list = []   #Список словарей game_info\n",
    "\n",
    "for link in list_of_links:\n",
    "    game_info = {}\n",
    "    try:\n",
    "        # значение header вашего браузера меняется на случайное из списка, чтобы труднее сойти за бота\n",
    "        ua = UserAgent()\n",
    "        header = {'User-Agent':str(ua.chrome)}         \n",
    "        htmlContent = requests.get(link, headers=header)\n",
    "        soup = BeautifulSoup(htmlContent.text)\n",
    "        \n",
    "        #Название игры\n",
    "        title = soup.find('h1',{'class':'gameObject__title'})  \n",
    "        title = re.sub('\\n','',str(title.text))\n",
    "        game_info['name'] = title .lower()   \n",
    "        \n",
    "        #Год выпуска\n",
    "        release_date = soup.find('ul', {'class':\"kubrick-info__releasedate\"}).find('li').find('span').text\n",
    "        # на сайте дата выхода игры указывается в полном формате, где 4 цифры года идут в конце,\n",
    "        #поэтому нужно найти 4 цифры, идущие подряд\n",
    "        year = int(re.search('[0-9]{4}',release_date).group())\n",
    "        game_info['year_of_release'] =  year        \n",
    "        \n",
    "        #Платформа\n",
    "        ultag = soup.find('div', {'class':\"gameObject__description\"}).find('ul',{'class':'system-list'})\n",
    "        platforms = [] #список платформ\n",
    "        #Непосредственно текст  содержит тег <li>\n",
    "        for li in ultag.find_all('li'):\n",
    "            platforms.append(li.text.lower()) #платформ может быть несколько, поэтому добавляем каждую в список\n",
    "        game_info['platform'] = platforms[0]  #главной будет первая        \n",
    "         \n",
    "        #Оценки\n",
    "        critic_score= soup.find('div',{'class':'reviewObject'}).find('dl',{'class':'reviewObject__metacritic'}).find('dd').text\n",
    "        if critic_score =='--':\n",
    "            game_info['critic_score'] = np.nan\n",
    "        else:\n",
    "            game_info['critic_score'] = int(critic_score)\n",
    "        user_score = soup.find('div',{'class':'reviewObject'}).find('dl',{'class':'reviewObject__userAvg'}).find('a').text\n",
    "        \n",
    "        game_info['user_score'] = float(user_score)\n",
    "        #main_list.append(game_info)  \n",
    "    except BaseException as e:\n",
    "        exception_list.append(\" Filename: {}, Link: {}, Error : {}\".format(names_links_pairs[link],link, str(e)))\n",
    "    main_list.append(game_info)\n",
    "#---------------------------------------------КОНЕЦ ПАРСЕРА-------------------------------------------    \n",
    "#print(main_list)\n",
    "#print(exception_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be82835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = r'Адрес к папке с файлами'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745869ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Файл с новой информацией к играм с пропусками\n",
    "try:\n",
    "    gamestop_data_2 = pd.read_csv(save_folder+r'\\gamestop_data_2.csv')\n",
    "except:\n",
    "    print(\"Укажите путь к файлу\")\n",
    "\n",
    "#Файл с проверочной информацией по играм, у которых нет пропуски, \n",
    "#но надо сравнить насколько отличаются оценки здесь и там на сайте\n",
    "try:\n",
    "    gamestop_data_val = pd.read_csv(save_folder+r'\\gamestop_data_val.csv')\n",
    "except:\n",
    "    print(\"Укажите путь к файлу\")\n",
    "\n",
    "#Файл для ленивых с объединенной информацией из предыдущих двух по полям name, platform.\n",
    "## Колонки, оканчивающиеся на _gs - данные с сайта по играм для таблицы gamestop_data_2\n",
    "##Колонки, оканчивающиеся на _val - данные с сайта по играм для таблицы gamestop_data_val\n",
    "try:\n",
    "    data_updated_full = pd.read_csv(save_folder+r'\\data_updated_full.csv')\n",
    "except:\n",
    "    print(\"Укажите путь к файлу\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6f1b5b1",
   "metadata": {},
   "source": [
    "## Парсер сайта ESRB.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd6e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Данные\n",
    "rating_off = data[data['rating'].isna()].reset_index()\n",
    "ratingDict_off = rating_off[['name','platform','year_of_release']].to_dict(orient = 'index')\n",
    "\n",
    "#Cловарь кодировок названий платформ согласно сайту, для тех кто не вошел сюда стоит значение Other\n",
    "platform_encoding = {'wiiu':'Wii U',\n",
    "                      'x360':'Xbox 360',\n",
    "                      'ps3':'PlayStation 3',\n",
    "                      'ps4':'PlayStation 4',\n",
    "                      'pc':'PC',\n",
    "                      '3ds':'Nintendo 3DS',\n",
    "                      'xone':'Xbox One'    \n",
    "}\n",
    "for name in data['platform'].unique():\n",
    "    if name not in platform_encoding.keys():\n",
    "        platform_encoding[name] = 'Other'\n",
    "        #platform_encoding[name] = 'All Platforms'\n",
    "        \n",
    "## Форматирование части ссылки, относящейся к платформе\n",
    "for key in platform_encoding:\n",
    "    platform_encoding[key] = re.sub(' ','%20', str(platform_encoding[key])) \n",
    "print(platform_encoding )\n",
    "\n",
    "Построитель ссылок:\n",
    "\n",
    "domain = 'https://www.esrb.org/search/?searchKeyword='\n",
    "rating_part = '&rating=E%2CE10%2B%2CT%2CM%2CAO&descriptor=All%20Content&'\n",
    "#page = 'pg=1'\n",
    "ending = '&searchType=All&ielement[]=all'\n",
    "pl_part = '&platform='\n",
    "formatted_names = []\n",
    "link_list_test = {}\n",
    "for key, dict_ in ratingDict_off.items():\n",
    "    d_temp = {}\n",
    "    name_form = str(dict_['name']).strip(' ')#str() нужно, чтобы символы вроде точек у цифр типа float etc были строковым типом \n",
    "    name_form = re.sub(' ', '%20', name_form)\n",
    "    if  '\\'' in dict_['name']: # проверка на наличие апострофа в слове\n",
    "        name_form = re.sub(\"\\'\", '%27', name_form)\n",
    "    if \":\" in dict_['name']:  # проверка на наличие двоеточия\n",
    "        name_form = re.sub(':', '%3A', name_form)\n",
    "    if \"!\" in dict_['name']: #проверка на наличие восклицательного знака\n",
    "        name_form = re.sub('!', '%21', name_form)    \n",
    "    if re.match(\"pokemon\\D+/pokemon\\D+\",dict_['name'] ): # in case of pokemon red/pokemon blue pattern\n",
    "        name_form = re.split(\"/\",name_form)[0] \n",
    "        #построение ссылки\n",
    "    link = domain + name_form+pl_part+platform_encoding[dict_['platform']]+rating_part\n",
    "    formatted_names.append(name_form)    \n",
    "    ratingDict_off[key]['link'] = link  #добавление ссылки в главный словарь под ключом \"link\"    \n",
    "#print(ratingDict_off)\n",
    "\n",
    "Парсер\n",
    "\n",
    "domain = 'https://www.esrb.org/search/?searchKeyword='\n",
    "rating_part = '&rating=E%2CE10%2B%2CT%2CM%2CAO&descriptor=All%20Content&'\n",
    "#page = 'pg=1'\n",
    "ending = '&searchType=All&ielement[]=all'\n",
    "pl_part = '&platform='\n",
    "main_list_off = {}\n",
    "exception_list_off = []\n",
    "for key, dict_ in  ratingDict_off.items():       \n",
    "    try:\n",
    "        \n",
    "        ua = UserAgent()\n",
    "        header = {'User-Agent':str(ua.chrome)}\n",
    "        for page in range(1,4):\n",
    "            htmlContent = requests.get(dict_['link']+\"pg={}\".format(page)+ending, headers=header)\n",
    "            #print(dict_['link']+\"pg={}\".format(page)+ending)\n",
    "            soup = BeautifulSoup(htmlContent.text)\n",
    "            found_titles = []\n",
    "            for tag in soup.find_all('div', {'id':'results'}):                \n",
    "                for tag in tag.find_all('div',{'class':'heading'}):\n",
    "                    title = tag.find('h2').text\n",
    "                    #temp = []\n",
    "                    #temp.append(title)\n",
    "                    #found_titles[key] = temp\n",
    "                    found_titles.append(title)            \n",
    "                ## Cортировка\n",
    "                    sorted_title = sorted(title.strip().lower())\n",
    "                #title_to_compare = ratingDict_on[0]['name']\n",
    "                    if re.match(\"pokemon\\D+/pokemon\\D+\",dict_['name']):\n",
    "                            title_to_compare = re.split(\"/\",dict_['name'])[0]\n",
    "                            #print('if pokemon case compare to:', title_to_compare)\n",
    "                    else:\n",
    "                            title_to_compare = dict_['name']\n",
    "                            #print('if not a pokemon case compare to: ', dict_['name'])\n",
    "                    sorted_title_compareTo = sorted(title_to_compare.strip().lower())\n",
    "                #Если найдено совпадение\n",
    "                    if sorted_title == sorted_title_compareTo:\n",
    "                            #print('title:', title,' compare to: ',title_to_compare )\n",
    "                            platform = tag.find('div',{'class':'platforms'})\n",
    "                            esrb = tag.parent.find('div',{'class':'content'}).find('img')\n",
    "                        #print(esrb.text)\n",
    "                            gathered_data = {}\n",
    "                            gathered_data['name_on_site'] = title.lower()\n",
    "                            gathered_data['platforms'] = platform.text.lower()\n",
    "                            gathered_data['rating'] = esrb['alt'].lower()\n",
    "                            #gathered_data['link'] = dict_['link']+\"pg={}\".format(page)+ending\n",
    "                            #print(gathered_data)\n",
    "                    else:\n",
    "                            continue\n",
    "        #print (found_titles)\n",
    "    except  BaseException as e:\n",
    "        exception_list_off.append(\" Filename: {}, Link: {}, Error : {}\".format(dict_['name'], dict_['link'], str(e)))    \n",
    "    ratingDict_off[key]['gathered_info'] = gathered_data\n",
    "    if gathered_data['name_on_site'] not in main_list_off.values():\n",
    "        main_list_off[key] = gathered_data\n",
    "#print(main_list_test)    \n",
    "       \n",
    "\n",
    "esrb_new = pd.DataFrame(main_list_off)\n",
    "parced_ESRB_full = pd.DataFrame(ratingDict_off)\n",
    "display(parced_ESRB_full.T.head())\n",
    "display(esrb_new.T.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1668529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## КОД ДЛЯ ПОЛУЧЕНИЯ НЕБОЛЬШОЙ СТАТИСТИКИ\n",
    "#data_updated_full = data_updated_full.drop_duplicates() ## в новых данных есть дубликаты\n",
    "#data_temp = data_updated_full[~data_updated_full.isnull().any(axis = 1)].query('user_score !=\"tbd\"')\n",
    "#data_temp ['user_score'] = data_temp ['user_score'].astype('float')\n",
    "#data_temp['diff_cs_pct'] = ((data_temp['critic_score'] - data_temp['critic_score_val'])/data_temp['critic_score_val']*100)\n",
    "#data_temp['diff_us_pct'] = (data_temp['user_score'] - data_temp['user_score_val'])/data_temp['user_score_val']*100\n",
    "#display(data_temp[['name','critic_score','critic_score_val','diff_cs_pct','user_score','user_score_val','diff_us_pct']])\n",
    "\n",
    "#Количество совпадений\n",
    "#print('Количество совпадений', data_temp[data_temp['critic_score']==data_temp['critic_score_val']]['name'].count())\n",
    "#display(data_temp['diff_cs_pct'].describe())\n",
    "#print(('Среднее отклонение значений user_score', data_temp['user_score'] - data_temp['user_score_val']).abs().mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
